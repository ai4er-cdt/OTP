{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from gsw.conversions import CT_from_pt\n",
    "from gsw.density import sigma2\n",
    "from geopy.distance import distance\n",
    "from scipy.integrate import simpson\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_depth(v: np.ndarray, \n",
    "              x_Z: np.ndarray, \n",
    "              x_lon: np.ndarray, \n",
    "              d: np.ndarray, \n",
    "              lat: int) -> np.ndarray:\n",
    "    _, n_lons, _, n_times = v.shape\n",
    "    ix = list(x_Z).index(d[lat])+1\n",
    "    moc = np.empty(n_times)\n",
    "    for t in range(n_times):\n",
    "        # inner integral over depth\n",
    "        inner = simpson(y=np.nan_to_num(v[lat, :, :ix, t]), x=x_Z[:ix], axis=1)\n",
    "        # outer integral over longitude\n",
    "        moc[t] = -simpson(y=inner, x=x_lon[lat, :]) / 1e6\n",
    "    return moc\n",
    "\n",
    "def lat_density(v: np.ndarray, \n",
    "                x_Z: np.ndarray, \n",
    "                x_lon: np.ndarray, \n",
    "                lighter: np.ndarray,\n",
    "                empty: np.ndarray,\n",
    "                isopycnals: np.ndarray,\n",
    "                lat: int) -> np.ndarray:\n",
    "    _, n_lons, _, n_times = v.shape\n",
    "    moc = np.empty(n_times)\n",
    "\n",
    "    for t in range(n_times):\n",
    "        for l in range(n_lons):\n",
    "            if not (lighter[lat, l, t] or empty[lat, l, t]):\n",
    "                ix = isopycnals[lat, l, t]\n",
    "            else:\n",
    "                ix = 0\n",
    "            v[lat, l, ix:, t] = 0.\n",
    "\n",
    "        # inner integral over depth\n",
    "        inner = simpson(y=v[lat, :, :, t], x=x_Z, axis=1)\n",
    "        # outer integral over longitude\n",
    "        moc[t] = -simpson(y=inner, x=x_lon[lat, :]) / 1e6\n",
    "    return moc\n",
    "\n",
    "def psi(d: float|np.ndarray, \n",
    "        v: np.ndarray, \n",
    "        x_lon: np.ndarray, \n",
    "        x_Z: np.ndarray,\n",
    "        s2: Optional[np.ndarray],\n",
    "        use_density: bool=False) -> np.ndarray:\n",
    "    n_lats, _, n_depths, _ = v.shape\n",
    "    d = np.array([d]*n_lats) if np.isscalar(d) else np.asarray(d)\n",
    "    assert len(d) == n_lats\n",
    "    if use_density:\n",
    "        # find water columns lighter than d\n",
    "        lighter = np.less_equal(s2[:, :, 0, :], d[:, np.newaxis, np.newaxis])\n",
    "        # find missing water columns\n",
    "        empty = np.isnan(s2).all(axis=2)\n",
    "        # find isopycnals (defaults to 0)\n",
    "        isopycnals = np.argmax(np.less_equal(s2, d[:, np.newaxis, np.newaxis, np.newaxis]), axis=2)\n",
    "        # any defaults (0 values) represent entire water columns which are heavier than d\n",
    "        isopycnals[isopycnals == 0] = n_depths\n",
    "        f = lat_density\n",
    "        _args = [v.copy(), x_Z, x_lon, lighter, empty, isopycnals]\n",
    "    else:\n",
    "        f = lat_depth\n",
    "        _args = [v, x_Z, x_lon, d]\n",
    "\n",
    "    # parallelise over latitudes\n",
    "    # NOTE: in my testing, I found that parallelising over latitudes was more efficient than any other dimension\n",
    "    with Pool(cpu_count()) as pool:\n",
    "            results = pool.starmap(f, [(*_args, lat) for lat in range(n_lats)]) \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bolus = True\n",
    "use_density = True\n",
    "density_precision = 100\n",
    "data_path = \"/mnt/g/My Drive/GTC/ecco_data\"\n",
    "outpath = \"/mnt/g/My Drive/GTC/_sf\"\n",
    "\n",
    "sections = [\"26N\", \"30S\", \"55S\", \"60S\"]\n",
    "coordinates = [\"latitude\", \"longitude\", \"Z\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching monthly mean velocities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching bolus velocities\n",
      "using density: fetching temperature and salinity for calculation\n",
      "loading data into memory\n",
      "calculating streamfunction for all densities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:16<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "saving moc to /mnt/g/My Drive/GTC/_sf/26N_moc_density.pickle\n",
      "fetching monthly mean velocities\n",
      "fetching bolus velocities\n",
      "using density: fetching temperature and salinity for calculation\n",
      "loading data into memory\n",
      "calculating streamfunction for all densities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:30<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "saving moc to /mnt/g/My Drive/GTC/_sf/30S_moc_density.pickle\n",
      "fetching monthly mean velocities\n",
      "fetching bolus velocities\n",
      "using density: fetching temperature and salinity for calculation\n",
      "loading data into memory\n",
      "calculating streamfunction for all densities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:57<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "saving moc to /mnt/g/My Drive/GTC/_sf/55S_moc_density.pickle\n",
      "fetching monthly mean velocities\n",
      "fetching bolus velocities\n",
      "using density: fetching temperature and salinity for calculation\n",
      "loading data into memory\n",
      "calculating streamfunction for all densities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:41<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "saving moc to /mnt/g/My Drive/GTC/_sf/60S_moc_density.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for section in sections:\n",
    "    print(\"fetching monthly mean velocities\")\n",
    "    vm = xr.open_mfdataset(f\"{data_path}_full/{section}/ECCO_L4_OCEAN_VEL_05DEG_MONTHLY_V4R4/*.nc\",\n",
    "                        coords=\"minimal\",\n",
    "                        data_vars=\"minimal\",\n",
    "                        parallel=True, compat=\"override\")\n",
    "    vm = vm[[\"NVEL\"]].transpose(*coordinates).isel(Z=slice(None, None, -1)).fillna(0.)\n",
    "    vm = vm.rename({\"NVEL\": \"vm\"})\n",
    "    if use_bolus:\n",
    "        print(\"fetching bolus velocities\")\n",
    "        ve = xr.open_mfdataset(f\"{data_path}_full/{section}/ECCO_L4_BOLUS_05DEG_MONTHLY_V4R4/*.nc\",\n",
    "                            coords=\"minimal\",\n",
    "                            data_vars=\"minimal\",\n",
    "                            parallel=True, compat=\"override\")\n",
    "        ve = ve[[\"NVELSTAR\"]].transpose(*coordinates).isel(Z=slice(None, None, -1)).fillna(0.)\n",
    "        ve = ve.rename({\"NVELSTAR\": \"ve\"})\n",
    "    if use_density:\n",
    "        print(\"using density: fetching temperature and salinity for calculation\")\n",
    "        density = xr.open_mfdataset(f\"{data_path}_full/{section}/ECCO_L4_TEMP_SALINITY_05DEG_MONTHLY_V4R4/*.nc\",\n",
    "                                    coords=\"minimal\",\n",
    "                                    data_vars=\"minimal\",\n",
    "                                    parallel=True, compat=\"override\")\n",
    "        density = density[[\"THETA\", \"SALT\"]].transpose(*coordinates).isel(Z=slice(None, None, -1))\n",
    "        ct = CT_from_pt(SA=density[\"SALT\"], pt=density[\"THETA\"])\n",
    "        s2 = sigma2(SA=density[\"SALT\"], CT=ct).to_dataset()\n",
    "        s2 = s2.rename({list(s2.data_vars)[0]: \"sigma_2\"})\n",
    "        \n",
    "    v = vm[\"vm\"] + ve[\"ve\"] if use_bolus else vm[\"vm\"]\n",
    "\n",
    "    time = vm[\"time\"].to_numpy()\n",
    "    grid = np.array([[(lat, lon) for lon in v[\"longitude\"].to_numpy()] for lat in v[\"latitude\"].to_numpy()])\n",
    "    # get x-coordinates of longitude measurements\n",
    "    x_lon = np.array([[0.]+[distance(latitude[i+1], latitude[i]).meters\n",
    "                            for i in range(grid.shape[1]-1)] \n",
    "                            for latitude in grid])\n",
    "    # rounding to cm\n",
    "    x_lon = np.round(np.cumsum(x_lon, -1), 2)\n",
    "    # get x-coordinates of depth measurements\n",
    "    x_Z = v[\"Z\"].to_numpy()\n",
    "    # unsure if -ve is a problem but getting rid of them just in case\n",
    "    x_Z += max(abs(x_Z))\n",
    "\n",
    "    print(\"loading data into memory\")\n",
    "    v_np = v.to_numpy()\n",
    "    if use_density:\n",
    "        s2_np = s2[\"sigma_2\"].to_numpy()\n",
    "        temp = s2_np.flatten()\n",
    "        temp = temp[~np.isnan(temp)]\n",
    "        sf_range = np.linspace(min(temp)-0.1, max(temp)+0.1, density_precision)\n",
    "        outfile = open(f\"{outpath}/{section}_density_range.pickle\", \"wb\")\n",
    "        pickle.dump(sf_range, outfile); outfile.close()\n",
    "    else:\n",
    "        s2_np = None\n",
    "        sf_range = x_Z\n",
    "\n",
    "    args = [v_np, x_lon, x_Z, s2_np, use_density]\n",
    "    # calculate the streamfunction at all possible densities/depths\n",
    "    if use_density: print(\"calculating streamfunction for all densities\")\n",
    "    else: print(\"calculating streamfunction for all depths\")\n",
    "    streamfunction = np.array([psi(d, *args) for d in tqdm(sf_range)])\n",
    "    if use_density:\n",
    "        outfile = open(f\"{outpath}/{section}_sf_density.pickle\", \"wb\")\n",
    "    else:\n",
    "        outfile = open(f\"{outpath}/{section}_sf_depth.pickle\", \"wb\")\n",
    "    pickle.dump(streamfunction[:, 1, :], outfile); outfile.close()\n",
    "    # find the density/depth with the largest absolute time-averaged streamfunction\n",
    "    d_0 = np.argmin(np.mean(streamfunction[:, 1, :], axis=-1), axis=0)\n",
    "    moc = streamfunction[d_0, 1, :]\n",
    "\n",
    "    outfile = f\"{outpath}/{section}_moc\"\n",
    "    outfile = f\"{outfile}_density.pickle\" if use_density else f\"{outfile}_depth.pickle\"\n",
    "    print(\"done!\")\n",
    "    print(f\"saving moc to {outfile}\")\n",
    "    outfile = open(outfile, \"wb\")\n",
    "    pickle.dump(moc, outfile); outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
