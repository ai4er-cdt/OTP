{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "from models.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(data: xr.core.dataset.Dataset, \n",
    "                   keep_coords: List=[\"time\", \"latitude\", \"longitude\"],\n",
    "                   avg_time_window: Optional[int]=None, \n",
    "                   history: Optional[int]=None,\n",
    "                   data_vars: List=[\"SSH\", \"SST\", \"SSS\", \"OBP\", \"ZWS\"],\n",
    "                   return_pt: bool=False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read in the original input dataset, with coordinates \"time\", \"latitude\", \"longitude\",\n",
    "    and data variables \"SSH\", \"SST\", \"SSS\", \"OBP\", \"ZWS\".\n",
    "\n",
    "    Return a numpy array of any subset of the data variables, optionally averaged over any coordinates or including history.\n",
    "    Can also return a pytorch tensor.\n",
    "\n",
    "    data: original xarray dataset - see solodoch_data_minimal in google drive.\n",
    "    keep_coords: coordinate axes to be kept. others will be averaged over and collapsed.\n",
    "    avg_time_window: if time is not included in keep_coords, optionally choose a lag over which to average.\n",
    "    history: include a new axis for history (useful if we want to convolve over past values for example)\n",
    "    data_vars: data variables to be kept.\n",
    "    return_pt: if true, returns a pytorch tensor (cpu!) instead of a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def moving_average(data: np.ndarray,\n",
    "                       lag: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate a moving average over the time dimension.\n",
    "\n",
    "        data: subset of values from original dataset. intermediate step of reshape_inputs.\n",
    "        lag: lag over which to average.\n",
    "        \"\"\"\n",
    "        # axis order is guaranteed due to reshape_inputs\n",
    "        n_times, n_lats, n_lons, n_features = data.shape\n",
    "        D = n_times - lag + 1\n",
    "        view_shape = (D, lag, n_lats, n_lons, n_features)\n",
    "        s = data.strides; strides = (s[0], s[0], s[1], s[2], s[3])\n",
    "        data_ = as_strided(data, shape=view_shape, strides=strides)\n",
    "        return data_.mean(axis=1).squeeze(axis=1)\n",
    "    \n",
    "    coords = [\"time\", \"latitude\", \"longitude\"]\n",
    "    data = data[coords + data_vars].to_array().values\n",
    "    data = data.transpose(1, 2, 3, 0)\n",
    "    for ax in coords:\n",
    "        if ax not in keep_coords: \n",
    "            if ax == \"time\" and avg_time_window != None: \n",
    "                data = moving_average(data, avg_time_window)\n",
    "            else:\n",
    "                data = data.mean(axis=coords.index(ax))\n",
    "            coords = [c for c in coords if c != ax]   \n",
    "\n",
    "    if history != None:\n",
    "        if \"time\" not in keep_coords: raise Exception(\"Error. 'time' must be in keep_coords in order to use history.\")  \n",
    "        coords = [\"time\", \"history\"] + coords[1:]\n",
    "        n_times = data.shape[0]\n",
    "        if history > n_times: raise ValueError(\"Desired history is longer than the full time series.\")\n",
    "        view_shape = (n_times-history+1, history, *data.shape[1:])      \n",
    "        s = data.strides[0]\n",
    "        data = as_strided(data, shape=view_shape, strides=(s, s, *data.strides[1:]))    \n",
    "\n",
    "    print(f\"axes: {coords + ['feature']}\")\n",
    "    print(f\"variables: {data_vars}\")\n",
    "    print(f\"shape: {data.shape}\")    \n",
    "    return t.Tensor(data) if return_pt else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 5\n",
    "\n",
    "n_times, n_lats, n_lons, n_features = foo.shape\n",
    "view_shape = (n_times-H+1, H, n_lats, n_lons, n_features)\n",
    "x, y, z, w = foo.strides\n",
    "bar = foo.as_strided(foo, shape=view_shape, strides=(x, x, y, z, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axes: ['time', 'history', 'feature']\n",
      "variables: ['SSH', 'SST', 'SSS', 'OBP', 'ZWS']\n",
      "shape: (1, 288, 5)\n"
     ]
    }
   ],
   "source": [
    "data_home = \"/mnt/g/My Drive/GTC/solodoch_data_minimal\"\n",
    "lats = [\"26N\", \"30S\", \"55S\", \"60S\"]\n",
    "lat = lats[0]\n",
    "data = xr.open_dataset(f\"{data_home}/{lat}.nc\")\n",
    "\n",
    "# apply whatever preprocessing we want *before* calling reshape_inputs\n",
    "pp_data = apply_preprocessing(data,\n",
    "                              mode=\"inputs\",\n",
    "                              remove_season=True,\n",
    "                              remove_trend=True,\n",
    "                              standardize=True,\n",
    "                              lowpass=True)\n",
    "\n",
    "# reshape as desired and convert to a numpy array\n",
    "pp_data_np = reshape_inputs(pp_data, keep_coords=[\"time\"], history=288, return_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0279,  1.0273,  1.3772, -0.1046,  3.3314],\n",
       "         [ 0.1325,  0.3698,  0.9208, -1.2171,  1.1591],\n",
       "         [-0.4907, -0.1333,  0.4977, -1.8350, -0.2081],\n",
       "         ...,\n",
       "         [-0.5665,  0.4738,  0.2288, -1.2381,  0.2949],\n",
       "         [-0.7330,  0.4428,  0.4530, -2.0619, -0.2224],\n",
       "         [-0.7610,  0.2743,  0.7834, -3.1836, -0.8352]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = reshape_inputs(pp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.strides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
